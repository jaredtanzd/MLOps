{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-21 22:27:48.645499: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-21 22:27:48.658180: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-21 22:27:48.666843: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-21 22:27:48.674658: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-21 22:27:48.862761: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-21 22:27:48.866015: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-21 22:27:48.868646: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-21 22:27:48.875105: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-21 22:27:48.881053: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-21 22:27:48.887324: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-21 22:27:48.949953: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-21 22:27:48.960984: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-21 22:28:14.838997: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-21 22:28:14.840257: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-21 22:28:14.841280: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-21 22:28:14.844402: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-21 22:28:14.845375: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-21 22:28:14.848082: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-21 22:28:14.848875: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-21 22:28:14.938086: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-21 22:28:14.939001: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-21 22:28:14.939829: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-21 22:28:14.940696: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-21 22:28:14.985989: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-21 22:29:08.347965: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-21 22:29:08.364986: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-21 22:29:08.366098: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-21 22:29:08.367807: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-21 22:29:08.368814: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-21 22:29:08.442560: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-21 22:29:08.443683: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-21 22:29:08.452527: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-21 22:29:08.453715: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-21 22:29:08.454535: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15711 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:01:00.0, compute capability: 8.0\n",
      "2024-03-21 22:29:08.461010: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-21 22:29:08.473758: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 15927 MB memory:  -> device: 1, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:41:00.0, compute capability: 8.0\n",
      "2024-03-21 22:29:08.505424: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-21 22:29:08.506926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 37648 MB memory:  -> device: 2, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:81:00.0, compute capability: 8.0\n",
      "2024-03-21 22:29:08.535326: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-21 22:29:08.536295: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 43814 MB memory:  -> device: 3, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:c1:00.0, compute capability: 8.0\n",
      "2024-03-21 22:29:58.262466: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 67s 67s/step\n",
      "1/1 [==============================] - 1s 589ms/step\n",
      "Drift detected: True\n",
      "Number of features with drift detected: 20124 / 50752\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from skimage import io\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Reshape, Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras import backend as K\n",
    "from scipy.stats import ks_2samp\n",
    "import tensorflow as tf\n",
    "\n",
    "# Function to load images from directory\n",
    "def load_images_from_directory(directory_path):\n",
    "    images = []\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('.tiff'):\n",
    "            img_path = os.path.join(directory_path, filename)\n",
    "            img = io.imread(img_path).astype(np.float32)  # Assuming images are already normalized\n",
    "            images.append(img.reshape((207, 243, 1)))  # Add channel dimension for grayscale\n",
    "    return np.array(images)\n",
    "\n",
    "# Define an untrained autoencoder architecture suitable for your image dimensions\n",
    "def build_autoencoder(input_shape=(207, 243, 1)):\n",
    "    input_img = Input(shape=input_shape)\n",
    "    \n",
    "    # Encoder\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "    encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    \n",
    "    # Decoder\n",
    "    x = Conv2DTranspose(16, (3, 3), strides=2, activation='relu', padding='same')(encoded)\n",
    "    x = Conv2DTranspose(32, (3, 3), strides=2, activation='relu', padding='same')(x)\n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "    \n",
    "    autoencoder = Model(input_img, decoded)\n",
    "    encoder = Model(input_img, encoded)\n",
    "    \n",
    "    return encoder, autoencoder\n",
    "\n",
    "def detect_drift(encoded_current, encoded_new):\n",
    "    # Flatten encoded representations to apply K-S test\n",
    "    flat_current = encoded_current.reshape((encoded_current.shape[0], -1))\n",
    "    flat_new = encoded_new.reshape((encoded_new.shape[0], -1))\n",
    "    \n",
    "    # Perform K-S test on flattened representations\n",
    "    p_values = [ks_2samp(flat_current[:, i], flat_new[:, i]).pvalue for i in range(flat_current.shape[1])]\n",
    "    \n",
    "    return np.array(p_values)\n",
    "\n",
    "# Set seed for reproducibility\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# Load images\n",
    "current_data = load_images_from_directory('data/test_current_data')\n",
    "new_data = load_images_from_directory('data/test_new_data')\n",
    "\n",
    "# Build autoencoder\n",
    "encoder, _ = build_autoencoder()\n",
    "\n",
    "# Encode images (using the untrained encoder)\n",
    "encoded_current = encoder.predict(current_data)\n",
    "encoded_new = encoder.predict(new_data)\n",
    "\n",
    "# Detect drift\n",
    "p_values = detect_drift(encoded_current, encoded_new)\n",
    "drift_detected = np.any(p_values < 0.05)\n",
    "\n",
    "# Output results\n",
    "print(f\"Drift detected: {drift_detected}\")\n",
    "print(f\"Number of features with drift detected: {np.sum(p_values < 0.05)} / {len(p_values)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from skimage import io\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Reshape, Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras import backend as K\n",
    "from scipy.stats import ks_2samp\n",
    "import tensorflow as tf\n",
    "\n",
    "# Function to load images from directory\n",
    "def load_images_from_directory(directory_path):\n",
    "    images = []\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('.tiff'):\n",
    "            img_path = os.path.join(directory_path, filename)\n",
    "            img = io.imread(img_path).astype(np.float32)  # Assuming images are already normalized\n",
    "            images.append(img.reshape((207, 243, 1)))  # Add channel dimension for grayscale\n",
    "    return np.array(images)\n",
    "\n",
    "# Define an untrained autoencoder architecture suitable for your image dimensions\n",
    "def build_autoencoder(input_shape=(207, 243, 1)):\n",
    "    input_img = Input(shape=input_shape)\n",
    "    \n",
    "    # Encoder\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "    encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    \n",
    "    # Decoder\n",
    "    x = Conv2DTranspose(16, (3, 3), strides=2, activation='relu', padding='same')(encoded)\n",
    "    x = Conv2DTranspose(32, (3, 3), strides=2, activation='relu', padding='same')(x)\n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "    \n",
    "    autoencoder = Model(input_img, decoded)\n",
    "    encoder = Model(input_img, encoded)\n",
    "    \n",
    "    return encoder, autoencoder\n",
    "\n",
    "def detect_drift(encoded_current, encoded_new):\n",
    "    # Flatten encoded representations to apply K-S test\n",
    "    flat_current = encoded_current.reshape((encoded_current.shape[0], -1))\n",
    "    flat_new = encoded_new.reshape((encoded_new.shape[0], -1))\n",
    "    \n",
    "    # Perform K-S test on flattened representations\n",
    "    p_values = [ks_2samp(flat_current[:, i], flat_new[:, i]).pvalue for i in range(flat_current.shape[1])]\n",
    "    \n",
    "    return np.array(p_values)\n",
    "\n",
    "# Set seed for reproducibility\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# Load images\n",
    "current_data = load_images_from_directory('data/processed/sorted_imgs')\n",
    "new_data = load_images_from_directory('data/oasis/ct_norm_resized')\n",
    "\n",
    "# Build autoencoder\n",
    "encoder, _ = build_autoencoder()\n",
    "\n",
    "# Encode images (using the untrained encoder)\n",
    "encoded_current = encoder.predict(current_data)\n",
    "encoded_new = encoder.predict(new_data)\n",
    "\n",
    "# Detect drift\n",
    "p_values = detect_drift(encoded_current, encoded_new)\n",
    "drift_detected = np.any(p_values < 0.05)\n",
    "\n",
    "# Output results\n",
    "print(f\"Drift detected: {drift_detected}\")\n",
    "print(f\"Number of features with drift detected: {np.sum(p_values < 0.05)} / {len(p_values)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/r200025/my_dvc_project/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:543: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drift detected:\n",
      "Number of features with drift detected: 1 / 10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from skimage import io\n",
    "from scipy.stats import ks_2samp\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "from statsmodels.stats.multitest import multipletests  # For Bonferroni correction\n",
    "\n",
    "def load_images_from_directory(directory_path):\n",
    "    \"\"\"\n",
    "    Load all .tiff images from a directory and return them as a numpy array.\n",
    "    Ensure images are loaded; otherwise, return None to indicate an issue.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('.tiff'):\n",
    "            img_path = os.path.join(directory_path, filename)\n",
    "            img = io.imread(img_path).astype(np.float32) / 255.0\n",
    "            images.append(img.flatten())  # Flatten each image to treat all pixels as features\n",
    "    if images:  # Check if any images were loaded\n",
    "        return np.array(images)\n",
    "    else:\n",
    "        print(f\"No images found in {directory_path}.\")\n",
    "        return None\n",
    "\n",
    "def apply_dimensionality_reduction(data, n_components=None):\n",
    "    \"\"\"\n",
    "    Apply PCA to the data. If n_components is not specified or exceeds the limit,\n",
    "    it defaults to the min(n_samples, n_features).\n",
    "    \"\"\"\n",
    "    if data is not None:\n",
    "        if n_components is None or n_components > min(data.shape):\n",
    "            n_components = min(data.shape)\n",
    "        pca = PCA(n_components=n_components)\n",
    "        return pca.fit_transform(data)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def detect_drift(current_data, new_data, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Perform feature-wise K-S tests and apply Bonferroni correction to the results.\n",
    "    \"\"\"\n",
    "    if current_data is not None and new_data is not None:\n",
    "        ks_results = [ks_2samp(current_data[:, i], new_data[:, i]).pvalue for i in range(current_data.shape[1])]\n",
    "        reject_list, corrected_p_values, _, _ = multipletests(ks_results, alpha=alpha, method='bonferroni')\n",
    "        return reject_list, corrected_p_values\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "# Load images\n",
    "current_data = load_images_from_directory('data/test_current_data')\n",
    "new_data = load_images_from_directory('data/test_new_data')\n",
    "\n",
    "if current_data is not None and new_data is not None:\n",
    "    # Apply dimensionality reduction\n",
    "    current_data_reduced = apply_dimensionality_reduction(current_data)\n",
    "    new_data_reduced = apply_dimensionality_reduction(new_data)\n",
    "\n",
    "    # Detect drift\n",
    "    reject_list, corrected_p_values = detect_drift(current_data_reduced, new_data_reduced)\n",
    "    \n",
    "    if reject_list is not None:\n",
    "        # Interpret and aggregate results\n",
    "        drift_detected = any(reject_list)\n",
    "        print(\"Drift detected:\" if drift_detected else \"No significant drift detected.\")\n",
    "        print(f\"Number of features with drift detected: {np.sum(reject_list)} / {len(reject_list)}\")\n",
    "    else:\n",
    "        print(\"Drift detection could not be performed due to data issues.\")\n",
    "else:\n",
    "    print(\"Image loading failed. Drift detection skipped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import io\n",
    "from scipy.stats import ks_2samp\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "from statsmodels.stats.multitest import multipletests  # For Bonferroni correction\n",
    "import random\n",
    "\n",
    "def load_images_from_directory(directory_path):\n",
    "    images = []\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('.tiff'):\n",
    "            img_path = os.path.join(directory_path, filename)\n",
    "            img = io.imread(img_path).astype(np.float32) / 255.0\n",
    "            images.append(img.flatten())\n",
    "    if images:\n",
    "        return np.array(images)\n",
    "    else:\n",
    "        print(f\"No images found in {directory_path}.\")\n",
    "        return None\n",
    "\n",
    "def apply_dimensionality_reduction(data, n_components=None):\n",
    "    if data is not None:\n",
    "        if n_components is None or n_components > min(data.shape):\n",
    "            n_components = min(data.shape)\n",
    "        pca = PCA(n_components=n_components)\n",
    "        return pca.fit_transform(data)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def detect_drift(current_data, new_data, alpha=0.05):\n",
    "    if current_data is not None and new_data is not None:\n",
    "        ks_results = [ks_2samp(current_data[:, i], new_data[:, i]).pvalue for i in range(current_data.shape[1])]\n",
    "        reject_list, corrected_p_values, _, _ = multipletests(ks_results, alpha=alpha, method='bonferroni')\n",
    "        return reject_list, corrected_p_values\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "def random_sampling(data, sample_size):\n",
    "    if data is None:\n",
    "        return None\n",
    "    if sample_size >= len(data):\n",
    "        return data  # Return original data if sample size is greater than dataset size\n",
    "    sample_indices = random.sample(range(len(data)), sample_size)\n",
    "    return data[sample_indices]\n",
    "\n",
    "# Parameters\n",
    "sample_size = 10  # Define your sample size here\n",
    "\n",
    "# Load images\n",
    "current_data = load_images_from_directory('data/processed/sorted_imgs/train')\n",
    "new_data = load_images_from_directory('data/oasis/ct_norm_resized')\n",
    "\n",
    "# Random sampling\n",
    "current_data_sampled = random_sampling(current_data, sample_size)\n",
    "new_data_sampled = random_sampling(new_data, sample_size)\n",
    "\n",
    "if current_data_sampled is not None and new_data_sampled is not None:\n",
    "    # Apply dimensionality reduction\n",
    "    current_data_reduced = apply_dimensionality_reduction(current_data_sampled)\n",
    "    new_data_reduced = apply_dimensionality_reduction(new_data_sampled)\n",
    "\n",
    "    # Detect drift\n",
    "    reject_list, corrected_p_values = detect_drift(current_data_reduced, new_data_reduced)\n",
    "    \n",
    "    if reject_list is not None:\n",
    "        drift_detected = any(reject_list)\n",
    "        print(\"Drift detected:\" if drift_detected else \"No significant drift detected.\")\n",
    "        print(f\"Number of features with drift detected: {np.sum(reject_list)} / {len(reject_list)}\")\n",
    "    else:\n",
    "        print(\"Drift detection could not be performed due to data issues.\")\n",
    "else:\n",
    "    print(\"Image loading or sampling failed. Drift detection skipped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transferred 100 images from data/processed/sorted_imgs/train to data/test_current_data.\n",
      "Transferred 100 images from data/oasis/ct_norm_resized to data/test_new_data.\n",
      "Drift detected:\n",
      "Number of features with drift detected: 46 / 100\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from skimage import io\n",
    "import os\n",
    "import random\n",
    "from scipy.stats import ks_2samp\n",
    "from sklearn.decomposition import PCA\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import shutil  # For copying files\n",
    "\n",
    "def clear_directory(directory_path):\n",
    "    \"\"\"\n",
    "    Removes all files in the specified directory.\n",
    "    \"\"\"\n",
    "    for filename in os.listdir(directory_path):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print(f'Failed to delete {file_path}. Reason: {e}')\n",
    "\n",
    "def sample_and_transfer_images(source_dir, target_dir, sample_size=100):\n",
    "    \"\"\"\n",
    "    Sample a number of images from the source directory and transfer them to the target directory.\n",
    "    Ensure the target directory is empty before transferring.\n",
    "    \"\"\"\n",
    "    # Clear the target directory first\n",
    "    clear_directory(target_dir)\n",
    "\n",
    "    filenames = [filename for filename in os.listdir(source_dir) if filename.endswith('.tiff')]\n",
    "    sampled_filenames = random.sample(filenames, min(sample_size, len(filenames)))\n",
    "\n",
    "    if not os.path.exists(target_dir):\n",
    "        os.makedirs(target_dir)\n",
    "    \n",
    "    for filename in sampled_filenames:\n",
    "        shutil.copy(os.path.join(source_dir, filename), os.path.join(target_dir, filename))\n",
    "        \n",
    "    print(f\"Transferred {len(sampled_filenames)} images from {source_dir} to {target_dir}.\")\n",
    "\n",
    "\n",
    "def load_images_from_directory(directory_path):\n",
    "    images = []\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('.tiff'):\n",
    "            img_path = os.path.join(directory_path, filename)\n",
    "            img = io.imread(img_path).astype(np.float32) / 255.0\n",
    "            images.append(img.flatten())\n",
    "            \n",
    "    if images:\n",
    "        return np.array(images)\n",
    "    else:\n",
    "        print(f\"No images found in {directory_path}.\")\n",
    "        return None\n",
    "\n",
    "def apply_dimensionality_reduction(data, n_components=None):\n",
    "    if data is not None:\n",
    "        if n_components is None or n_components > min(data.shape):\n",
    "            n_components = min(data.shape)\n",
    "        pca = PCA(n_components=n_components)\n",
    "        return pca.fit_transform(data)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def detect_drift(current_data, new_data, alpha=0.05):\n",
    "    if current_data is not None and new_data is not None:\n",
    "        ks_results = [ks_2samp(current_data[:, i], new_data[:, i]).pvalue for i in range(current_data.shape[1])]\n",
    "        reject_list, corrected_p_values, _, _ = multipletests(ks_results, alpha=alpha, method='bonferroni')\n",
    "        return reject_list, corrected_p_values\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "# Sample and transfer images to new directories for processing\n",
    "current_data_dir = 'data/processed/sorted_imgs/train'\n",
    "new_data_dir = 'data/oasis/ct_norm_resized'\n",
    "sample_and_transfer_images(current_data_dir, 'data/test_current_data')\n",
    "sample_and_transfer_images(new_data_dir, 'data/test_new_data')\n",
    "\n",
    "# Load images\n",
    "current_data = load_images_from_directory('data/test_current_data')\n",
    "new_data = load_images_from_directory('data/test_new_data')\n",
    "\n",
    "# Proceed with processing if data was successfully loaded\n",
    "if current_data is not None and new_data is not None:\n",
    "    current_data_reduced = apply_dimensionality_reduction(current_data)\n",
    "    new_data_reduced = apply_dimensionality_reduction(new_data)\n",
    "\n",
    "    reject_list, corrected_p_values = detect_drift(current_data_reduced, new_data_reduced)\n",
    "\n",
    "    drift_detected = any(reject_list)\n",
    "    print(\"Drift detected:\" if drift_detected else \"No significant drift detected.\")\n",
    "    print(f\"Number of features with drift detected: {np.sum(reject_list)} / {len(reject_list)}\")\n",
    "else:\n",
    "    print(\"Image loading failed. Drift detection skipped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
